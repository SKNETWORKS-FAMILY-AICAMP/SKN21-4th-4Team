from src.schema.state import AgentState
from src.retrievals.search_agent import execute_dual_query_search
from src.retrievals.search_router import build_search_config

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from src.utils.config import ConfigLLM
from src.prompts import CONDENSE_QUESTION_PROMPT
from src.retrievals.reranker import Reranker
from src.utils.search_utils import is_korean, translate_to_english

def rewrite_query(original_query: str, messages: list) -> str:
    """
    ëŒ€í™” ê¸°ë¡ì´ ìˆëŠ” ê²½ìš°, ì´ì „ ë§¥ë½ì„ ë°˜ì˜í•˜ì—¬ ì§ˆë¬¸ì„ ì¬ì‘ì„±í•©ë‹ˆë‹¤.
    """
    if not messages or len(messages) <= 1:
        return original_query

    # ëŒ€í™” ê¸°ë¡ í¬ë§·íŒ… (ìµœê·¼ 3ê°œ í„´ë§Œ ì‚¬ìš©í•˜ê±°ë‚˜ ì „ì²´ ì‚¬ìš©)
    # LangGraphì˜ messagesëŠ” (type, content) íŠœí”Œ ë¦¬ìŠ¤íŠ¸ì¼ ìˆ˜ë„ ìˆê³ , BaseMessage ê°ì²´ ë¦¬ìŠ¤íŠ¸ì¼ ìˆ˜ë„ ìˆìŒ.
    # ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
    formatted_history = []
    
    # ë§ˆì§€ë§‰ ë©”ì‹œì§€ëŠ” í˜„ì¬ ì¿¼ë¦¬ì´ë¯€ë¡œ ì œì™¸í•˜ê³  ì´ì „ ê¸°ë¡ë§Œ ì‚¬ìš©
    history_messages = messages[:-1] 
    
    for msg in history_messages[-6:]: # ìµœê·¼ 6ê°œ ë©”ì‹œì§€ (3í„´) ì°¸ì¡°
        if hasattr(msg, 'content'):
            role = "Human" if msg.type == 'human' else "Assistant"
            formatted_history.append(f"{role}: {msg.content}")
        elif isinstance(msg, tuple):
            role = "Human" if msg[0] == 'human' else "Assistant"
            formatted_history.append(f"{role}: {msg[1]}")
            
    history_str = "\n".join(formatted_history)

    # print("===== START history_str =====", flush=True)
    # print(history_str, flush=True)
    # print("===== END history_str =====", flush=True)

    # LLM ì„¤ì •
    llm = ChatOpenAI(model=ConfigLLM.OPENAI_MODEL, temperature=0)
    prompt = ChatPromptTemplate.from_template(CONDENSE_QUESTION_PROMPT)
    chain = prompt | llm | StrOutputParser()
    
    try:
        rewritten_query = chain.invoke({
            "chat_history": history_str,
            "question": original_query
        })
        print(f"ğŸ”„ [Rewrite Query] Original: '{original_query}' -> Rewritten: '{rewritten_query}'")
        return rewritten_query
    except Exception as e:
        print(f"âš ï¸ Query Rewrite Failed: {e}")
        return original_query


def search_node(state: AgentState):
    """
    LangGraph ë…¸ë“œìš© í•¨ìˆ˜
    stateì—ì„œ queryë¥¼ ì½ê³ , ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°˜í™˜
    """
    
    original_query = state['query']
    messages = state.get('messages', [])

    query = rewrite_query(original_query, messages)

    english_query = ""
    if len(query) > 0 and is_korean(query):
        # 2. ë²ˆì—­(ì˜ì–´ í‚¤ì›Œë“œ) ê²€ìƒ‰
        english_query = translate_to_english(query)

    # ê²€ìƒ‰ ì„¤ì • ê²°ì •
    config = build_search_config(query)
    
    # ì§ˆë¬¸ ìœ íš¨ì„± ì²´í¬
    if not config.get('is_valid', True):  # ê¸°ë³¸ê°’ True (ê¸°ì¡´ í˜¸í™˜ì„±)
        print("âš ï¸ ì§ˆë¬¸ì´ í•™ìŠµ ìë£Œì™€ ê´€ë ¨ì´ ì—†ì–´ ê²€ìƒ‰ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return {
            'search_results': []
        }
    
    # ê²€ìƒ‰ ì„¤ì • ë° ì‹¤í–‰ (í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê¸°ë³¸ ì ìš©)
    results, query_info = execute_dual_query_search(query, english_query)
    
    # ê²°ê³¼ í¬ë§·íŒ…
    search_results = [
        {
            "english_query": english_query,
            "content": r['content'],
            "score": round(r['score'], 4),
            "metadata": r['metadata']
        }
        for r in results
    ]
    
    return {
        'search_results': search_results,
        'search_top_k': config.get('top_k', ConfigLLM.TOP_K)
    }
    
    
def rerank_node(state: AgentState):
    """
    search_nodeì—ì„œ 1ì°¨ ì„ ë³„ëœ ê²°ê³¼(search_results)ë¥¼ 
    Cross-Encoder ëª¨ë¸ë¡œ ì •ë°€ ì¬ì •ë ¬(Reranking)í•©ë‹ˆë‹¤.
    """
    query = state['query']
    results = state.get('search_results', [])
    
    # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
    if not results:
        return {"search_results": []}

    # ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚° (Inference)
    reranker = Reranker(top_k=state.get('search_top_k', ConfigLLM.TOP_K))
    reranked_results = reranker.invoke(query, results)

    # ê²°ê³¼ í¬ë§·íŒ…
    search_results = [
        {
            "content": "=== [ë‚´ë¶€ ìë£Œ (Original)] === \n\n" + r['content'],
            "score": round(r['score'], 4),
            "metadata": r['metadata']
        }
        for r in reranked_results
    ]

    return {
        "search_results": search_results
    }


def build_context(state: AgentState):
    """
    ë³´ê³ ì„œ ì‘ì„±: LLMì´ ì½ê¸° ì¢‹ê²Œ ë¬¸ì¥ìœ¼ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.
    """

    results = state['search_results']
    
    if not results:
        return {"context": "ê²€ìƒ‰ëœ ê´€ë ¨ ìë£Œê°€ ì—†ìŠµë‹ˆë‹¤."}
    
    context_parts = []
    
    for i, res in enumerate(results, 1): # ë²ˆí˜¸ëŠ” 1ë²ˆë¶€í„°
        source = res['metadata'].get('source', 'Unknown')
        code_snippet = res['metadata'].get('code_snippet')

        score = round(res['score'], 2)
        content = res['content'].strip()
        
        part = f"[Original {i}] ì¶œì²˜: {source} (ìœ ì‚¬ë„: {score})\n{content}"
        if code_snippet:
            part += f"\n\nì½”ë“œ ì˜ˆì œ:\n```python\n{code_snippet}\n```"
            
            print("===== code_snippet =====")
            print(code_snippet)
            print("===== code_snippet =====")

        context_parts.append(part)
        
    context = "\n\n---\n\n".join(context_parts)


    return {"context": context}